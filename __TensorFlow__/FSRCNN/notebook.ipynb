{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TENSORFLOW IMPLEMENTATION\n",
    "\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, color\n",
    "import cv2\n",
    "\n",
    "\n",
    "SF = 2   #scaling factor, i.e. how much do you want to scale your image (here, twice of original image)\n",
    "\n",
    "ip_height = 160\n",
    "ip_width = 240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "#there are total of 100 images (i chose 50 for training and 20 are for testing)\n",
    "#but i am not using all of them \n",
    "\n",
    "temp1 = io.imread_collection('C:/Users/adity/Desktop/sai/*_SRF_2_LR.png')\n",
    "temp2 = io.imread_collection('C:/Users/adity/Desktop/sai/*_SRF_2_HR.png')\n",
    "\n",
    "x_ = np.array([images for i,images in enumerate(temp1)],dtype =np.float32).reshape(-1,160,240,1)\n",
    "y_ = np.array([images for i,images in enumerate(temp2)],dtype= np.float32).reshape(-1,1,320*480)\n",
    "\n",
    "xx = np.array(x_).astype(np.float32)   #x is tensor - (160, 240,1)\n",
    "yy = np.array(y_).astype(np.float32)   #y is a vector- (1,320*480)\n",
    "'''\n",
    "\n",
    "change these numbers according to your\n",
    "train and test set sizes....\n",
    "\n",
    "'''\n",
    "xtest =np.array(x_[:1])        #test set\n",
    "ytest =np.array(y_[:1])\n",
    "\n",
    "xx=xx[1:9]                        #train set\n",
    "yy=yy[1:9]\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, 160, 240, 1),name=\"X\" )        # input\n",
    "Y = tf.placeholder(tf.float32,shape=(None, 1, 320*480),name=\"Y\" )      # actual output\n",
    "print(len(xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W, b, strides=1, act_fn = 1):\n",
    "    # Conv2D wrapper, with bias and relu activation(only if act_fn=1)\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    if act_fn ==1:\n",
    "        return tf.nn.relu(x)\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def dil_conv2d(x, W, b, rate=2):\n",
    "    # Dilation Conv2D wrapper, with bias but no activation\n",
    "    x = tf.nn.atrous_conv2d(x, W , rate, padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Store layer's weight & bias   ------   weights here are equivalent to 'filters' in tensorflow\n",
    "\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    def CNN(X):\n",
    "        weights = {\n",
    "            # 5x5 conv, 1 input, 32 outputs                             FEATURE REP.\n",
    "            'wc1': tf.Variable(tf.random_normal([3, 3, 1, 32])*0.0008,name='wc1',dtype=tf.float32),\n",
    "\n",
    "            # 5x5 conv, 32 inputs, 32 outputs                           SHRINKING\n",
    "            'wc2': tf.Variable(tf.random_normal([3, 3, 32, 16])*0.0008,'wc2',dtype=tf.float32),\n",
    "\n",
    "            # 5x5 conv, 32 inputs, 16 outputs                           NON-LINEAR MAPPING\n",
    "            'wc3': tf.Variable(tf.random_normal([3, 3, 16, 32])*0.0008, 'wc3',dtype=tf.float32),\n",
    "            # 3X3 dilation conv, 16 inputs, 16 outputs                  NON-LINEAR MAPPING\n",
    "            'wd1': tf.Variable(tf.random_normal([3, 3, 32,32])*0.0008,'wd1',dtype=tf.float32),\n",
    "            # 5x5 conv, 32 inputs, 16 outputs                           NON-LINEAR MAPPING\n",
    "            'wc4': tf.Variable(tf.random_normal([3, 3, 32,32])*0.0008,'wc4',dtype=tf.float32),\n",
    "            # 3X3 dilation conv, 16 inputs, 16 outputs                  NON-LINEAR MAPPING\n",
    "            'wd2': tf.Variable(tf.random_normal([3, 3, 32,32])*0.0008,'wd2',dtype=tf.float32),\n",
    "            # 5x5 conv, 32 inputs, 16 outputs                           NON-LINEAR MAPPING\n",
    "            'wc5': tf.Variable(tf.random_normal([3, 3, 32,16])*0.0008,'wc5',dtype=tf.float32),\n",
    "\n",
    "            # 5x5 conv, 16 inputs, 64 outputs                           EXPANSION\n",
    "            'wc6': tf.Variable(tf.random_normal([3, 3, 16, 32])*0.0008,'wc6',dtype=tf.float32),\n",
    "\n",
    "        }\n",
    "\n",
    "        biases = {\n",
    "            'bc1': tf.Variable(tf.random_normal([32]),dtype=tf.float32),    #FEATURE REPRESENTATION\n",
    "\n",
    "            'bc2': tf.Variable(tf.random_normal([16]),dtype=tf.float32),     #SHRINKING\n",
    "\n",
    "            'bc3': tf.Variable(tf.random_normal([32]),dtype=tf.float32),     #NON-LINEAR MAPPING\n",
    "            'bd1': tf.Variable(tf.random_normal([32]),dtype=tf.float32),     #NON-LINEAR MAPPING\n",
    "            'bc4': tf.Variable(tf.random_normal([32]),dtype=tf.float32),     #NON-LINEAR MAPPING\n",
    "            'bd2': tf.Variable(tf.random_normal([32]),dtype=tf.float32),     #NON-LINEAR MAPPING\n",
    "            'bc5': tf.Variable(tf.random_normal([16]),dtype=tf.float32),     #NON-LINEAR MAPPING\n",
    "\n",
    "            'bc6': tf.Variable(tf.random_normal([32]),dtype=tf.float32),    #EXPANSION\n",
    "        }\n",
    "\n",
    "        X = tf.cast(tf.reshape(X, shape=[-1, 160, 240, 1]),tf.float32)\n",
    "\n",
    "        c1 = conv2d(X, weights['wc1'], biases['bc1'])    #FEATURE REP\n",
    "\n",
    "        c2 = conv2d(c1, weights['wc2'], biases['bc2'])          #SHRINKING\n",
    "\n",
    "        c3 = conv2d(c2, weights['wc3'], biases['bc3'])          #NON-LINEAR MAPPING\n",
    "        d1 = dil_conv2d(c3, weights['wd1'], biases['bd1'])\n",
    "        c4 = conv2d(d1, weights['wc4'], biases['bc4'])\n",
    "        d2 = dil_conv2d(c4, weights['wd2'], biases['bd2'])\n",
    "        c5 = conv2d(d2, weights['wc5'], biases['bc5'])\n",
    "\n",
    "        c6 = conv2d(c5, weights['wc6'], biases['bc6'], act_fn =0)     #EXPANSION (LOCAL QUEUE JUMPING)\n",
    "        c6 = tf.add(c1,c6)\n",
    "        c6 = tf.nn.relu(c6)\n",
    "                                                                #DECONVOLUTION\n",
    "        op_image =tf.contrib.layers.conv2d_transpose(c6, num_outputs=1, kernel_size=(3,3), stride=2, padding=\"same\")\n",
    "        op_image = tf.reshape(op_image, ( -1,1, 320*480),\"op_image\")     #reshape the o/p image to a vector\n",
    "\n",
    "        return op_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/gpu:0\"):\n",
    "    def train_cnn(X):\n",
    "        prediction = CNN(X)\n",
    "        print(prediction)\n",
    "        #mse\n",
    "        loss = tf.reduce_mean(tf.pow(tf.subtract(prediction, Y), 2.0))\n",
    "        #optimizer\n",
    "        train1 = tf.train.AdamOptimizer(0.005).minimize(loss)\n",
    "        train2 = tf.train.AdamOptimizer(0.0009).minimize(loss)\n",
    "        train3 = tf.train.AdamOptimizer(0.0005).minimize(loss)\n",
    "        # i used same optimizers with different learning rate.\n",
    "        \n",
    "        \n",
    "        with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            for epoch in range(20):\n",
    "                l = sess.run(loss, feed_dict={X: xx, Y: yy})\n",
    "                sess.run(train1, feed_dict={X: xx, Y: yy})\n",
    "                print('Epoch', epoch+1, 'completed,  loss:\\t', l)\n",
    "                \n",
    "            for epoch in range(20,45):\n",
    "                l = sess.run(loss, feed_dict={X: xx, Y: yy})\n",
    "                sess.run(train2, feed_dict={X: xx, Y: yy})\n",
    "                print('Epoch', epoch+1, 'completed,  loss:\\t', l)\n",
    "                \n",
    "            for epoch in range(45,70):\n",
    "                l = sess.run(loss, feed_dict={X: xx, Y: yy})\n",
    "                sess.run(train3, feed_dict={X: xx, Y: yy})\n",
    "                print('Epoch', epoch+1, 'completed,  loss:\\t', l)\n",
    "                \n",
    "            print(\"\\n TEST ERROR : \", sess.run(loss, feed_dict={X: xtest, Y: ytest}))\n",
    "            \n",
    "            a = sess.run(prediction, feed_dict={X: xtest} )\n",
    "            b = np.array(a,dtype = np.uint8).reshape(1,80,120)\n",
    "            \n",
    "            for i in range(1):\n",
    "                #save images in directory\n",
    "                str = 'C:/Users/adity/Desktop/op_img_{0}_SRF_2_HR'.format(i)+'.png'\n",
    "                cv2.imwrite(str,b[i])\n",
    "                #show images\n",
    "                fig = plt.figure()\n",
    "                plt.imshow(b[i], cmap ='gray')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"op_image_3:0\", shape=(?, 1, 153600), dtype=float32)\n",
      "Epoch 1 completed,  loss:\t 16574.5\n",
      "Epoch 2 completed,  loss:\t 15528.3\n",
      "Epoch 3 completed,  loss:\t 14228.9\n",
      "Epoch 4 completed,  loss:\t 11941.6\n",
      "Epoch 5 completed,  loss:\t 6737.02\n",
      "Epoch 6 completed,  loss:\t 85436.7\n",
      "Epoch 7 completed,  loss:\t 4886.78\n",
      "Epoch 8 completed,  loss:\t 8674.23\n",
      "Epoch 9 completed,  loss:\t 10453.2\n",
      "Epoch 10 completed,  loss:\t 11340.4\n",
      "Epoch 11 completed,  loss:\t 11707.2\n",
      "Epoch 12 completed,  loss:\t 11874.1\n",
      "Epoch 13 completed,  loss:\t 11942.5\n",
      "Epoch 14 completed,  loss:\t 11959.5\n",
      "Epoch 15 completed,  loss:\t 11917.3\n"
     ]
    }
   ],
   "source": [
    "train_cnn(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
